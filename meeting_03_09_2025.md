# Meeting Gist ‚Äì Compositionality in Video Understanding

## üìå Context
We are exploring how to extend the **base paper**  
*"Not Only Text: Exploring Compositionality of Visual Representations in Vision-Language Models"*:contentReference[oaicite:1]{index=1}  
to the **video domain**. The goal is to investigate whether compositional structures (like object‚Äìattribute or object‚Äìaction combinations) also emerge in **video embeddings**, beyond static images.

---

## üó£Ô∏è Key Points from Discussion
- **Datasets mentioned:**
  - **EPIC-Kitchens** ‚Äì large-scale egocentric kitchen activity dataset.
  - **EMDB** ‚Äì Everyday Movement and Daily Behavior dataset (focused on natural human actions).
  - **C2C** (Concept-to-Concept) ‚Äì compositional video dataset.
  
- **Models/tools mentioned:**
  - **VideoLLaVA / Video-Language Models** ‚Äì strong candidates for extracting embeddings from videos.
  - Discussion around other **video embedding models** for compositional reasoning.
  - Consideration of **hierarchical image feature extraction** as a useful principle to adapt to temporal/video settings.

- **Research direction:**
  - Investigate **inside-video compositionality**:
    - What is a person doing?
    - How can actions be broken down into primitive components (objects + verbs)?
    - Can unseen compositions (e.g., ‚Äúcutting a fruit with a fork‚Äù) be inferred from known primitives?

---

## üéØ My Task (for the day)
- **Reproduce the results of the base paper**:
  - Implement **Geodesically Decomposable Embeddings (GDE)** framework from the paper.
  - Verify compositional classification and group robustness results on the reported **image datasets** (e.g., MIT-States, UT-Zappos, Waterbirds, CelebA).
  - Prepare baselines to compare against CLIP zero-shot and linearly decomposable embeddings.

---

## ‚úÖ Next Steps
- Once image-based results are validated, adapt the pipeline to **video datasets** (EPIC-Kitchens, EMDB, C2C).
- Explore whether temporal embeddings (from VideoLLaVA or similar models) also show **geodesic decomposability** in latent space.
- Plan experiments on **compositional action recognition** and **robustness to unseen action-object combinations**.

